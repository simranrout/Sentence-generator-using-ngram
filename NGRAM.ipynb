{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "380"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = \"\"\"Global warming or climate change has become a worldwide concern. It is gradually developing into an unprecedented environmental crisis evident in melting glaciers, changing weather patterns, rising sea levels, floods, cyclones and droughts. Global warming implies an increase in the average temperature of the Earth due to entrapment of greenhouse gases in the earth’s atmosphere.\"\"\"\n",
    "len(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "text\n",
    "n=5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## character ngram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "ngram={}\n",
    "for i in range(len(text)-n):\n",
    "    gram=text[i:i+n]\n",
    "    if gram  not in ngram.keys():\n",
    "        ngram[gram]=[]\n",
    "    ngram[gram].append(text[i+n])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing character model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Global warming or climate change has become a worldwide concern. It is gradually developing into an unprecedented environmental crisis evident in melting glaciers, changing weather patterns, rising sea levels, floods, cyclones an increase in the earth’s atmosphere.'"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "currentgram=text[0:n]\n",
    "result=currentgram\n",
    "for i in range(300):\n",
    "    if currentgram not in ngram.keys():\n",
    "        break\n",
    "    temp=ngram[currentgram]\n",
    "    temp1=temp[random.randrange(len(temp))]\n",
    "    result+=temp1\n",
    "    currentgram=result[len(result)-n:len(result)]\n",
    "\n",
    "result  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Globa': ['l', 'l'],\n",
       " 'lobal': [' ', ' '],\n",
       " 'obal ': ['w', 'w'],\n",
       " 'bal w': ['a', 'a'],\n",
       " 'al wa': ['r', 'r'],\n",
       " 'l war': ['m', 'm'],\n",
       " ' warm': ['i', 'i'],\n",
       " 'warmi': ['n', 'n'],\n",
       " 'armin': ['g', 'g'],\n",
       " 'rming': [' ', ' '],\n",
       " 'ming ': ['o', 'i'],\n",
       " 'ing o': ['r'],\n",
       " 'ng or': [' '],\n",
       " 'g or ': ['c'],\n",
       " ' or c': ['l'],\n",
       " 'or cl': ['i'],\n",
       " 'r cli': ['m'],\n",
       " ' clim': ['a'],\n",
       " 'clima': ['t'],\n",
       " 'limat': ['e'],\n",
       " 'imate': [' '],\n",
       " 'mate ': ['c'],\n",
       " 'ate c': ['h'],\n",
       " 'te ch': ['a'],\n",
       " 'e cha': ['n'],\n",
       " ' chan': ['g', 'g'],\n",
       " 'chang': ['e', 'i'],\n",
       " 'hange': [' '],\n",
       " 'ange ': ['h'],\n",
       " 'nge h': ['a'],\n",
       " 'ge ha': ['s'],\n",
       " 'e has': [' '],\n",
       " ' has ': ['b'],\n",
       " 'has b': ['e'],\n",
       " 'as be': ['c'],\n",
       " 's bec': ['o'],\n",
       " ' beco': ['m'],\n",
       " 'becom': ['e'],\n",
       " 'ecome': [' '],\n",
       " 'come ': ['a'],\n",
       " 'ome a': [' '],\n",
       " 'me a ': ['w'],\n",
       " 'e a w': ['o'],\n",
       " ' a wo': ['r'],\n",
       " 'a wor': ['l'],\n",
       " ' worl': ['d'],\n",
       " 'world': ['w'],\n",
       " 'orldw': ['i'],\n",
       " 'rldwi': ['d'],\n",
       " 'ldwid': ['e'],\n",
       " 'dwide': [' '],\n",
       " 'wide ': ['c'],\n",
       " 'ide c': ['o'],\n",
       " 'de co': ['n'],\n",
       " 'e con': ['c'],\n",
       " ' conc': ['e'],\n",
       " 'conce': ['r'],\n",
       " 'oncer': ['n'],\n",
       " 'ncern': ['.'],\n",
       " 'cern.': [' '],\n",
       " 'ern. ': ['I'],\n",
       " 'rn. I': ['t'],\n",
       " 'n. It': [' '],\n",
       " '. It ': ['i'],\n",
       " ' It i': ['s'],\n",
       " 'It is': [' '],\n",
       " 't is ': ['g'],\n",
       " ' is g': ['r'],\n",
       " 'is gr': ['a'],\n",
       " 's gra': ['d'],\n",
       " ' grad': ['u'],\n",
       " 'gradu': ['a'],\n",
       " 'radua': ['l'],\n",
       " 'adual': ['l'],\n",
       " 'duall': ['y'],\n",
       " 'ually': [' '],\n",
       " 'ally ': ['d'],\n",
       " 'lly d': ['e'],\n",
       " 'ly de': ['v'],\n",
       " 'y dev': ['e'],\n",
       " ' deve': ['l'],\n",
       " 'devel': ['o'],\n",
       " 'evelo': ['p'],\n",
       " 'velop': ['i'],\n",
       " 'elopi': ['n'],\n",
       " 'lopin': ['g'],\n",
       " 'oping': [' '],\n",
       " 'ping ': ['i'],\n",
       " 'ing i': ['n', 'm'],\n",
       " 'ng in': ['t'],\n",
       " 'g int': ['o'],\n",
       " ' into': [' '],\n",
       " 'into ': ['a'],\n",
       " 'nto a': ['n'],\n",
       " 'to an': [' '],\n",
       " 'o an ': ['u'],\n",
       " ' an u': ['n'],\n",
       " 'an un': ['p'],\n",
       " 'n unp': ['r'],\n",
       " ' unpr': ['e'],\n",
       " 'unpre': ['c'],\n",
       " 'nprec': ['e'],\n",
       " 'prece': ['d'],\n",
       " 'reced': ['e'],\n",
       " 'ecede': ['n'],\n",
       " 'ceden': ['t'],\n",
       " 'edent': ['e'],\n",
       " 'dente': ['d'],\n",
       " 'ented': [' '],\n",
       " 'nted ': ['e'],\n",
       " 'ted e': ['n'],\n",
       " 'ed en': ['v'],\n",
       " 'd env': ['i'],\n",
       " ' envi': ['r'],\n",
       " 'envir': ['o'],\n",
       " 'nviro': ['n'],\n",
       " 'viron': ['m'],\n",
       " 'ironm': ['e'],\n",
       " 'ronme': ['n'],\n",
       " 'onmen': ['t'],\n",
       " 'nment': ['a'],\n",
       " 'menta': ['l'],\n",
       " 'ental': [' '],\n",
       " 'ntal ': ['c'],\n",
       " 'tal c': ['r'],\n",
       " 'al cr': ['i'],\n",
       " 'l cri': ['s'],\n",
       " ' cris': ['i'],\n",
       " 'crisi': ['s'],\n",
       " 'risis': [' '],\n",
       " 'isis ': ['e'],\n",
       " 'sis e': ['v'],\n",
       " 'is ev': ['i'],\n",
       " 's evi': ['d'],\n",
       " ' evid': ['e'],\n",
       " 'evide': ['n'],\n",
       " 'viden': ['t'],\n",
       " 'ident': [' '],\n",
       " 'dent ': ['i'],\n",
       " 'ent i': ['n'],\n",
       " 'nt in': [' '],\n",
       " 't in ': ['m'],\n",
       " ' in m': ['e'],\n",
       " 'in me': ['l'],\n",
       " 'n mel': ['t'],\n",
       " ' melt': ['i'],\n",
       " 'melti': ['n'],\n",
       " 'eltin': ['g'],\n",
       " 'lting': [' '],\n",
       " 'ting ': ['g'],\n",
       " 'ing g': ['l'],\n",
       " 'ng gl': ['a'],\n",
       " 'g gla': ['c'],\n",
       " ' glac': ['i'],\n",
       " 'glaci': ['e'],\n",
       " 'lacie': ['r'],\n",
       " 'acier': ['s'],\n",
       " 'ciers': [','],\n",
       " 'iers,': [' '],\n",
       " 'ers, ': ['c'],\n",
       " 'rs, c': ['h'],\n",
       " 's, ch': ['a'],\n",
       " ', cha': ['n'],\n",
       " 'hangi': ['n'],\n",
       " 'angin': ['g'],\n",
       " 'nging': [' '],\n",
       " 'ging ': ['w'],\n",
       " 'ing w': ['e'],\n",
       " 'ng we': ['a'],\n",
       " 'g wea': ['t'],\n",
       " ' weat': ['h'],\n",
       " 'weath': ['e'],\n",
       " 'eathe': ['r'],\n",
       " 'ather': [' '],\n",
       " 'ther ': ['p'],\n",
       " 'her p': ['a'],\n",
       " 'er pa': ['t'],\n",
       " 'r pat': ['t'],\n",
       " ' patt': ['e'],\n",
       " 'patte': ['r'],\n",
       " 'atter': ['n'],\n",
       " 'ttern': ['s'],\n",
       " 'terns': [','],\n",
       " 'erns,': [' '],\n",
       " 'rns, ': ['r'],\n",
       " 'ns, r': ['i'],\n",
       " 's, ri': ['s'],\n",
       " ', ris': ['i'],\n",
       " ' risi': ['n'],\n",
       " 'risin': ['g'],\n",
       " 'ising': [' '],\n",
       " 'sing ': ['s'],\n",
       " 'ing s': ['e'],\n",
       " 'ng se': ['a'],\n",
       " 'g sea': [' '],\n",
       " ' sea ': ['l'],\n",
       " 'sea l': ['e'],\n",
       " 'ea le': ['v'],\n",
       " 'a lev': ['e'],\n",
       " ' leve': ['l'],\n",
       " 'level': ['s'],\n",
       " 'evels': [','],\n",
       " 'vels,': [' '],\n",
       " 'els, ': ['f'],\n",
       " 'ls, f': ['l'],\n",
       " 's, fl': ['o'],\n",
       " ', flo': ['o'],\n",
       " ' floo': ['d'],\n",
       " 'flood': ['s'],\n",
       " 'loods': [','],\n",
       " 'oods,': [' '],\n",
       " 'ods, ': ['c'],\n",
       " 'ds, c': ['y'],\n",
       " 's, cy': ['c'],\n",
       " ', cyc': ['l'],\n",
       " ' cycl': ['o'],\n",
       " 'cyclo': ['n'],\n",
       " 'yclon': ['e'],\n",
       " 'clone': ['s'],\n",
       " 'lones': [' '],\n",
       " 'ones ': ['a'],\n",
       " 'nes a': ['n'],\n",
       " 'es an': ['d', ' '],\n",
       " 's and': [' '],\n",
       " ' and ': ['d'],\n",
       " 'and d': ['r'],\n",
       " 'nd dr': ['o'],\n",
       " 'd dro': ['u'],\n",
       " ' drou': ['g'],\n",
       " 'droug': ['h'],\n",
       " 'rough': ['t'],\n",
       " 'ought': ['s'],\n",
       " 'ughts': ['.'],\n",
       " 'ghts.': [' '],\n",
       " 'hts. ': ['G'],\n",
       " 'ts. G': ['l'],\n",
       " 's. Gl': ['o'],\n",
       " '. Glo': ['b'],\n",
       " ' Glob': ['a'],\n",
       " 'ng im': ['p'],\n",
       " 'g imp': ['l'],\n",
       " ' impl': ['i'],\n",
       " 'impli': ['e'],\n",
       " 'mplie': ['s'],\n",
       " 'plies': [' '],\n",
       " 'lies ': ['a'],\n",
       " 'ies a': ['n'],\n",
       " 's an ': ['i'],\n",
       " ' an i': ['n'],\n",
       " 'an in': ['c'],\n",
       " 'n inc': ['r'],\n",
       " ' incr': ['e'],\n",
       " 'incre': ['a'],\n",
       " 'ncrea': ['s'],\n",
       " 'creas': ['e'],\n",
       " 'rease': [' '],\n",
       " 'ease ': ['i'],\n",
       " 'ase i': ['n'],\n",
       " 'se in': [' '],\n",
       " 'e in ': ['t'],\n",
       " ' in t': ['h', 'h'],\n",
       " 'in th': ['e', 'e'],\n",
       " 'n the': [' ', ' '],\n",
       " ' the ': ['a', 'E', 'e'],\n",
       " 'the a': ['v'],\n",
       " 'he av': ['e'],\n",
       " 'e ave': ['r'],\n",
       " ' aver': ['a'],\n",
       " 'avera': ['g'],\n",
       " 'verag': ['e'],\n",
       " 'erage': [' '],\n",
       " 'rage ': ['t'],\n",
       " 'age t': ['e'],\n",
       " 'ge te': ['m'],\n",
       " 'e tem': ['p'],\n",
       " ' temp': ['e'],\n",
       " 'tempe': ['r'],\n",
       " 'emper': ['a'],\n",
       " 'mpera': ['t'],\n",
       " 'perat': ['u'],\n",
       " 'eratu': ['r'],\n",
       " 'ratur': ['e'],\n",
       " 'ature': [' '],\n",
       " 'ture ': ['o'],\n",
       " 'ure o': ['f'],\n",
       " 're of': [' '],\n",
       " 'e of ': ['t'],\n",
       " ' of t': ['h'],\n",
       " 'of th': ['e'],\n",
       " 'f the': [' '],\n",
       " 'the E': ['a'],\n",
       " 'he Ea': ['r'],\n",
       " 'e Ear': ['t'],\n",
       " ' Eart': ['h'],\n",
       " 'Earth': [' '],\n",
       " 'arth ': ['d'],\n",
       " 'rth d': ['u'],\n",
       " 'th du': ['e'],\n",
       " 'h due': [' '],\n",
       " ' due ': ['t'],\n",
       " 'due t': ['o'],\n",
       " 'ue to': [' '],\n",
       " 'e to ': ['e'],\n",
       " ' to e': ['n'],\n",
       " 'to en': ['t'],\n",
       " 'o ent': ['r'],\n",
       " ' entr': ['a'],\n",
       " 'entra': ['p'],\n",
       " 'ntrap': ['m'],\n",
       " 'trapm': ['e'],\n",
       " 'rapme': ['n'],\n",
       " 'apmen': ['t'],\n",
       " 'pment': [' '],\n",
       " 'ment ': ['o'],\n",
       " 'ent o': ['f'],\n",
       " 'nt of': [' '],\n",
       " 't of ': ['g'],\n",
       " ' of g': ['r'],\n",
       " 'of gr': ['e'],\n",
       " 'f gre': ['e'],\n",
       " ' gree': ['n'],\n",
       " 'green': ['h'],\n",
       " 'reenh': ['o'],\n",
       " 'eenho': ['u'],\n",
       " 'enhou': ['s'],\n",
       " 'nhous': ['e'],\n",
       " 'house': [' '],\n",
       " 'ouse ': ['g'],\n",
       " 'use g': ['a'],\n",
       " 'se ga': ['s'],\n",
       " 'e gas': ['e'],\n",
       " ' gase': ['s'],\n",
       " 'gases': [' '],\n",
       " 'ases ': ['i'],\n",
       " 'ses i': ['n'],\n",
       " 'es in': [' '],\n",
       " 's in ': ['t'],\n",
       " 'the e': ['a'],\n",
       " 'he ea': ['r'],\n",
       " 'e ear': ['t'],\n",
       " ' eart': ['h'],\n",
       " 'earth': ['’'],\n",
       " 'arth’': ['s'],\n",
       " 'rth’s': [' '],\n",
       " 'th’s ': ['a'],\n",
       " 'h’s a': ['t'],\n",
       " '’s at': ['m'],\n",
       " 's atm': ['o'],\n",
       " ' atmo': ['s'],\n",
       " 'atmos': ['p'],\n",
       " 'tmosp': ['h'],\n",
       " 'mosph': ['e'],\n",
       " 'osphe': ['r'],\n",
       " 'spher': ['e'],\n",
       " 'phere': ['.']}"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ngram"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# word ngram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "n1=3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "ngram1={}\n",
    "words=nltk.word_tokenize(text)\n",
    "for i in range(len(words)-n1):\n",
    "    gram=' '.join(words[i:i+n1])\n",
    "    if gram not in ngram1.keys():\n",
    "        ngram1[gram]=[]\n",
    "    ngram1[gram].append(words[i+n1])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Global warming or': ['climate'],\n",
       " 'warming or climate': ['change'],\n",
       " 'or climate change': ['has'],\n",
       " 'climate change has': ['become'],\n",
       " 'change has become': ['a'],\n",
       " 'has become a': ['worldwide'],\n",
       " 'become a worldwide': ['concern'],\n",
       " 'a worldwide concern': ['.'],\n",
       " 'worldwide concern .': ['It'],\n",
       " 'concern . It': ['is'],\n",
       " '. It is': ['gradually'],\n",
       " 'It is gradually': ['developing'],\n",
       " 'is gradually developing': ['into'],\n",
       " 'gradually developing into': ['an'],\n",
       " 'developing into an': ['unprecedented'],\n",
       " 'into an unprecedented': ['environmental'],\n",
       " 'an unprecedented environmental': ['crisis'],\n",
       " 'unprecedented environmental crisis': ['evident'],\n",
       " 'environmental crisis evident': ['in'],\n",
       " 'crisis evident in': ['melting'],\n",
       " 'evident in melting': ['glaciers'],\n",
       " 'in melting glaciers': [','],\n",
       " 'melting glaciers ,': ['changing'],\n",
       " 'glaciers , changing': ['weather'],\n",
       " ', changing weather': ['patterns'],\n",
       " 'changing weather patterns': [','],\n",
       " 'weather patterns ,': ['rising'],\n",
       " 'patterns , rising': ['sea'],\n",
       " ', rising sea': ['levels'],\n",
       " 'rising sea levels': [','],\n",
       " 'sea levels ,': ['floods'],\n",
       " 'levels , floods': [','],\n",
       " ', floods ,': ['cyclones'],\n",
       " 'floods , cyclones': ['and'],\n",
       " ', cyclones and': ['droughts'],\n",
       " 'cyclones and droughts': ['.'],\n",
       " 'and droughts .': ['Global'],\n",
       " 'droughts . Global': ['warming'],\n",
       " '. Global warming': ['implies'],\n",
       " 'Global warming implies': ['an'],\n",
       " 'warming implies an': ['increase'],\n",
       " 'implies an increase': ['in'],\n",
       " 'an increase in': ['the'],\n",
       " 'increase in the': ['average'],\n",
       " 'in the average': ['temperature'],\n",
       " 'the average temperature': ['of'],\n",
       " 'average temperature of': ['the'],\n",
       " 'temperature of the': ['Earth'],\n",
       " 'of the Earth': ['due'],\n",
       " 'the Earth due': ['to'],\n",
       " 'Earth due to': ['entrapment'],\n",
       " 'due to entrapment': ['of'],\n",
       " 'to entrapment of': ['greenhouse'],\n",
       " 'entrapment of greenhouse': ['gases'],\n",
       " 'of greenhouse gases': ['in'],\n",
       " 'greenhouse gases in': ['the'],\n",
       " 'gases in the': ['earth'],\n",
       " 'in the earth': ['’'],\n",
       " 'the earth ’': ['s'],\n",
       " 'earth ’ s': ['atmosphere'],\n",
       " '’ s atmosphere': ['.']}"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ngram1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TESTING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "testword=' '.join(words[0:n1])\n",
    "result1=testword"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Global warming or climate change has become a worldwide concern . It is gradually developing into an unprecedented environmental crisis evident in melting glaciers , changing weather patterns , rising sea levels ,'"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i in range(30):\n",
    "    if testword not in ngram1.keys():\n",
    "        break\n",
    "    var=ngram1[testword]\n",
    "    var1=var[random.randrange(len(var))]\n",
    "    result1+=' '+var1\n",
    "    result2=nltk.word_tokenize(result1)\n",
    "    testword=' '.join(result2[len(result2)-n1:len(result2)])\n",
    "result1  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
